{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCdGFvtyItIK"
   },
   "source": [
    "# GAN overriding `Model.train_step`\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2019/04/29<br>\n",
    "**Last modified:** 2020/04/29<br>\n",
    "**Description:** A simple DCGAN trained using `fit()` by overriding `train_step`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZn7_uCAItIM"
   },
   "source": [
    "## Загрузка модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPbdfnz4ItIO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eL0jLVLItIV"
   },
   "source": [
    "## строим MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "r_5cxeh_ItIW",
    "outputId": "7c21f5e7-1df9-4990-ae83-0d9275ba9866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# MNIST \n",
    "batch_size = 64\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9GINZz5ItIb"
   },
   "source": [
    "## Строим discriminator\n",
    "\n",
    "размер карты 28x28 и бинарная классификация (настоящее изображение или генерировано)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "K99eZdkgItIc",
    "outputId": "ffe1e069-903c-4d25-a949-39836efc424b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 74,625\n",
      "Trainable params: 74,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eodbCQ1WItIh"
   },
   "source": [
    "## Строим generator\n",
    "\n",
    "обратное по отношению к дискриминатору преобразование, меняем `Conv2D` на `Conv2DTranspose` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "PY5lCMxqItIi",
    "outputId": "8a7250f8-828a-4680-b3db-7715cbaf6b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              809088    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 1)         6273      \n",
      "=================================================================\n",
      "Total params: 1,339,905\n",
      "Trainable params: 1,339,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        # строим размер входного вектора 7x7x128 map\n",
    "        layers.Dense(7 * 7 * 128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpX7dJvAItIn"
   },
   "source": [
    "## Класс со своим этапом обучения `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHP6aHUfItIo"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "        # берем случайный пример из скрытого пространства\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Строим по нему фейковое изображение\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # собрали с реальным в текзор\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # задаем метки 1 и 0 соответственно\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Добавляем шум !!!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # учим discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        #Выбрали случайный пример в скрытом пространстве\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # собрали метки реальных изображений\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Учим generator !\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4rYDb3qItIs"
   },
   "source": [
    "## Callback для сохранения изображений по ходу обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QoLCvAe7ItIt"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiMWOk1_ItIz"
   },
   "source": [
    "## Учим end-to-end модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "HZSj0hUHItI0",
    "outputId": "50bed419-8b60-4f00-e885-c14ab562b840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1094/1094 [==============================] - 57s 53ms/step - d_loss: 0.3527 - g_loss: 1.8106\n",
      "Epoch 2/3\n",
      "1094/1094 [==============================] - 58s 53ms/step - d_loss: 0.3195 - g_loss: 2.1867\n",
      "Epoch 3/3\n",
      "1094/1094 [==============================] - 58s 53ms/step - d_loss: 0.6625 - g_loss: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa05d224198>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cKqdR6bOItI4"
   },
   "source": [
    "Display the last generated images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "zZa20XZYItI5",
    "outputId": "0c8ba226-995f-422c-ea2b-e3633b437e42"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABZUlEQVR4nL2RvUtCYRTGn/d+pJduQn4kmAhR4GA42FAQQSA4mAQ1NIX/QNAWNAXt/gEtrSHYEDS1NEgfS0MNkYJFoRBKitxreFPvuS0Xu93r0tJZzsvz4znnPLzA/xcbvjzybLmpA2AC6TYYW6tslV5OxenkCd8wNcHs/PpCRt3wJIKbn/WCfbwr32691jpXKvUijt2+RrfbVi5WS7285IDbmq41ysuL6iD5I3Jm0xvKzVKimqXipcPoOizsTzDmq2lRZ9zJVFTkBfnoq+xk4N3CmBzeVbS0VTVzMlEKBFYyH61rKzQPYmT44rFQ/43nmN3JSONUN9DRdozgnjj53rdAQ0eneqc09VDYl+u755tWCAAsMuVVcvdkQIg/9nu/D547e3649QDAuV4RbWk4f/FpBgCyRG2XI2z4AAC8RJR0MAjHack/ICL7UAAYV4nIMGj4Z5yV1gHoKa47wghIIXmk/vf6Bva+fLfwpQpQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABFUlEQVR4nGNgGOSAkwWJw4gsw6oRrbF36j9smhjNN7/++vMpD0IEagoTE09MtJjot79s3L/RJBktE3w4uH88ZGHgZtz6E9U85qIvv79/f54pYXPyz1VGVDlGrSOfnzRJMjEwSH//vxdFiomVS9pMg4uBgYGBKernHyFUSSYmJiiT7eyPk6hy//79g3mM/f8mX1RJJLaE6p/XqJJIruP7M+M/qiQSV/7lJQZcgGV7F8wYRk50uQef1WFyvVVMqA5KEzxyG8osc/qCajlbbDo7lCk+t4cJRY6B2WuzBAMDAwMTC4e2LSualYyr/vx6cWzatZc3owXR9DEwMLhe+fHr14OZCZwInyOFARu3+pc7P7B5kmTACABtpU/czLom1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABoElEQVR4nGNgoAlgxBDhUGa4/Qu7YoVlV99/fRuIVU7wzs+fP/58N8KUYRZIPP7u98e3k7wYUe3k8Ixg5REV52X9+Wrm9G//0XTtf/Xx/fev39/caFJgwnCtd4iCotDfL493T3/1DybGAmOc/O16w4735+55b+FycEkZYyM2PUaWP2IMfxnQJXXb5X+w8/1+8O3qm3/okuwbJZn//fj67evee0gaoZKu4r/+/b105Bfr55f/GP+jSrKq7au9x/abP9TpxS2Wf3+YuFk+/IdJMkacWvGCgZGdTUlM0If96AdGQ9vjp7/8Z2BgYmBgYN524vm/f///8isKf2Y4++n/30cfJYNgRgvLMzKxKOb7H/7ycJogAwMDA4PgbD9oMDEV7xZm87v59++/fy+5IUJKv16zQez8p2p27YcMI+N/hs/qXyGS/j93/YEaK/Hrz99///796YPZI/PqRSTcPwpPf9+8nKsJ5/d9WIOUfHQmOPEihcy7X9MZcAH+J9dtkIIPFXBdW3+V8T8WCQYGBiaTKDFmBgYGbOmWUZL9/SdIvAEAiEqhad7tOm8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\"generated_img_0_2.png\"))\n",
    "display(Image(\"generated_img_1_2.png\"))\n",
    "display(Image(\"generated_img_2_2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "WruOaC0ahMZr",
    "outputId": "af689676-8946-429d-e60b-4474c02f76a1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAsUlEQVR4nK2SOQ7CMBBFv01ETUGPwp2RqLkJpwhtroBokKJ5FFmYSZyIgt9Y9pvVMzI5VQb+ofFQFthMsM6OkVUhaCq6mKzdDFrDjPpASGQPc2CKSYOlJIA3XMf7bnrvve/edvyTZakZlZsbcm7CQQ+ZJAvBp77BADh7WPdnxyQHhyrhIhlgaJxHckYZkkRamw2Y6/dbbT5IN0mvhU+nfWsy49T/VHGTnsV0f9HG5v6sD51zYkT33PHSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB4UlEQVR4nG2Su2sUYRTFf99jZl+zJmhkAytJRBFNNIqpFBciiiiKRQqxsIq9qJ1/gEV6K0UQm4CNjY12FgZBJIqFBB9ZiyWbxMeuzE52NzPfZzFJZga81Tn33Hsu3Hup7C67AglQvN74cFUAgBBKOnE6jrkgfOcmFEebhHzNsbCZEsMUpmnCG2nupFzpsjSaFlMulSVj7qVrUQmsGdOt8v8YioyZV5lUYnOhberlnXQ+2ylefp8tbZP7ZyQgpJCDjgTspRdNb2s95ZE5CViUKsSTxj6uz265DYcbFQB0YfriGLCn0fk16cTiE2MOxsidN6a999jnKFybjjt3hSacAtCEM4jycq/o/3g63l1es3Ba8GcVQMuRnmM3vrw1D3szN/Ov7gY2fwe6PoAuBo8mb7cCT61PTFRFrfa6r54dKQoLQGnfQM4TSmhVeN7vvdmvlBq6tvK4BCCle77gaK2tyNVDfvdsFP1c/DZaBtBXjp4YzjXHH3Q4fFbZv00D1F0jhAXd8vxFfbye6xj/U3V1wQBsnip0LIDrKYHnSnnoVhC1D2TWLUM/svh9YxqXsdHJzNHkzoPplW7AuaRNCVckdQODU0Hr/fbjCGl1SkQCyafqqJg5uBTJSIHUMqvaHWgFhX/HgaRAy/WtrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABZUlEQVR4nL2RvUtCYRTGn/d+pJduQn4kmAhR4GA42FAQQSA4mAQ1NIX/QNAWNAXt/gEtrSHYEDS1NEgfS0MNkYJFoRBKitxreFPvuS0Xu93r0tJZzsvz4znnPLzA/xcbvjzybLmpA2AC6TYYW6tslV5OxenkCd8wNcHs/PpCRt3wJIKbn/WCfbwr32691jpXKvUijt2+RrfbVi5WS7285IDbmq41ysuL6iD5I3Jm0xvKzVKimqXipcPoOizsTzDmq2lRZ9zJVFTkBfnoq+xk4N3CmBzeVbS0VTVzMlEKBFYyH61rKzQPYmT44rFQ/43nmN3JSONUN9DRdozgnjj53rdAQ0eneqc09VDYl+u755tWCAAsMuVVcvdkQIg/9nu/D547e3649QDAuV4RbWk4f/FpBgCyRG2XI2z4AAC8RJR0MAjHack/ICL7UAAYV4nIMGj4Z5yV1gHoKa47wghIIXmk/vf6Bva+fLfwpQpQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(\"generated_img_0_0.png\"))\n",
    "display(Image(\"generated_img_0_1.png\"))\n",
    "display(Image(\"generated_img_0_2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-o1cIfLhXhq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_overriding_train_step.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
